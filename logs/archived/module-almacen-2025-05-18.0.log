{"@timestamp":"2025-05-18T07:17:48.862902469-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:48.952463907-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 684114 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:48.952860145-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:48.953255319-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:49.392204927-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:49.488794652-05:00","@version":"1","message":"Finished Spring Data repository scanning in 90 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:50.065137006-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:51.497538897-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:53.027700023-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 4.98 seconds (process running for 8.601)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:53.030700168-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:53.061106507-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:53.061728181-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:53.137690603-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:53.681499214-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:53.734357173-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-5","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:53.840924819-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-5","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:53.871721888-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-5","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:53.886352912-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-5","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:53.897637674-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-5","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:17:54.003207983-05:00","@version":"1","message":"Custom destroy method 'dispose' on bean with name 'connectionFactory' propagated an exception: reactor.netty.channel.AbortedException: Connection has been closed BEFORE send operation","logger_name":"org.springframework.beans.factory.support.DisposableBeanAdapter","thread_name":"SpringApplicationShutdownHook","level":"WARN","level_value":30000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:07.437575514-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:07.497530227-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 694329 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:07.497985446-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:07.498424654-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:07.934269779-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:08.022140122-05:00","@version":"1","message":"Finished Spring Data repository scanning in 81 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:08.591901374-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:10.070092919-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:11.50575556-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 4.868 seconds (process running for 8.479)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:11.50872509-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:11.537987842-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:11.538520259-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:11.60785371-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:12.205016594-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:12.243498103-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-5","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:12.321693431-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-5","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:12.34759812-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-5","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:12.362616853-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-5","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:12.373204395-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-5","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T07:33:12.471460292-05:00","@version":"1","message":"Custom destroy method 'dispose' on bean with name 'connectionFactory' propagated an exception: reactor.netty.channel.AbortedException: Connection has been closed BEFORE send operation","logger_name":"org.springframework.beans.factory.support.DisposableBeanAdapter","thread_name":"SpringApplicationShutdownHook","level":"WARN","level_value":30000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:01.930308715-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:02.019453537-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 799787 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:02.020056386-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:02.020848002-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:02.616903551-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:02.686376887-05:00","@version":"1","message":"Finished Spring Data repository scanning in 64 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:03.455722387-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:05.138752641-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:06.569390813-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 5.362 seconds (process running for 10.192)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:06.572796715-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:06.602583165-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:06.602924402-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:06.671105616-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:07.039861451-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:07.173455854-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:07.272392102-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:07.314782205-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:07.32919205-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:07.343700317-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:27:07.418576489-05:00","@version":"1","message":"Custom destroy method 'dispose' on bean with name 'connectionFactory' propagated an exception: reactor.netty.channel.AbortedException: io.netty.channel.StacklessClosedChannelException","logger_name":"org.springframework.beans.factory.support.DisposableBeanAdapter","thread_name":"SpringApplicationShutdownHook","level":"WARN","level_value":30000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:00.034235946-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:00.100444247-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 801471 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:00.101023412-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:00.101608004-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:00.606807129-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:00.684902169-05:00","@version":"1","message":"Finished Spring Data repository scanning in 72 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:01.307586518-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:02.797128848-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:04.37331267-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 4.924 seconds (process running for 9.165)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:04.376296614-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:04.416844284-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:04.417366777-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:04.496239157-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:04.836789375-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:04.941092762-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:05.018487404-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:05.047161606-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:05.059839294-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:05.069130302-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:05.09449627-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T10:29:05.100532088-05:00","@version":"1","message":"Error no esperado al guardar la orden: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"ERROR","level_value":40000,"stack_trace":"org.springframework.dao.DataAccessResourceFailureException: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen\n\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxOnErrorResume] :\n\treactor.core.publisher.Flux.onErrorMap\n\torg.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\nError has been observed at the following site(s):\n\t*__Flux.onErrorMap ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\n\t|_                 ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.all(DefaultFetchSpec.java:76)\n\t|_       Flux.last ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_    Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$6(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$7(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:504)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.insert(R2dbcEntityTemplate.java:497)\n\t|_                 ⇢ at org.springframework.data.r2dbc.repository.support.SimpleR2dbcRepository.save(SimpleR2dbcRepository.java:122)\n\t|_                 ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.lambda$decorate$1(RepositoryMethodInvoker.java:222)\n\t*___Mono.usingWhen ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.decorate(RepositoryMethodInvoker.java:219)\nOriginal Stack Trace:\n\t\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\t\tat org.springframework.r2dbc.core.DefaultDatabaseClient.lambda$inConnectionMany$8(DefaultDatabaseClient.java:157)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorMap$29(Flux.java:7353)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorResume$30(Flux.java:7406)\n\t\tat reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.deferredError(FluxUsingWhen.java:403)\n\t\tat reactor.core.publisher.FluxUsingWhen$RollbackInner.onComplete(FluxUsingWhen.java:480)\n\t\tat reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2231)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onComplete(MonoIgnoreElements.java:89)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onComplete(FluxMapFuseable.java:152)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onComplete(FluxFilterFuseable.java:171)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onComplete(FluxFilterFuseable.java:391)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onComplete(FluxMapFuseable.java:350)\n\t\tat reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2573)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.request(FluxMapFuseable.java:360)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.request(FluxFilterFuseable.java:411)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.request(FluxFilterFuseable.java:191)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onSubscribe(MonoIgnoreElements.java:72)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onSubscribe(FluxFilterFuseable.java:87)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onSubscribe(FluxFilterFuseable.java:305)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onSubscribe(FluxMapFuseable.java:265)\n\t\tat reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:53)\n\t\tat reactor.core.publisher.Mono.subscribe(Mono.java:4576)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onError(FluxUsingWhen.java:368)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.checkTerminated(FluxFlatMap.java:846)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:612)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:592)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.innerError(FluxFlatMap.java:867)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapInner.onError(FluxFlatMap.java:994)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onError(FluxHandleFuseable.java:229)\n\t\tat reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onError(MonoFlatMapMany.java:256)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:201)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: io.r2dbc.postgresql.ExceptionFactory$PostgresqlNonTransientResourceException: El motivo no coincide con el almacen\n\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxHandleFuseable] :\n\treactor.core.publisher.Flux.handle\n\tio.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\nError has been observed at the following site(s):\n\t*_______Flux.handle ⇢ at io.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\n\t*__Mono.flatMapMany ⇢ at io.r2dbc.postgresql.PostgresqlStatement.lambda$execute$8(PostgresqlStatement.java:220)\n\t|_      Flux.handle ⇢ at io.r2dbc.postgresql.PostgresqlResult.map(PostgresqlResult.java:113)\n\t*______Flux.flatMap ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.lambda$all$1(DefaultFetchSpec.java:78)\n\t*____Flux.usingWhen ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:144)\nOriginal Stack Trace:\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:65)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.handleErrorResponse(ExceptionFactory.java:132)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:179)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\n","application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:45.339994053-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:45.418269377-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 828178 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:45.418899601-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:45.419466391-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:45.933406916-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:45.975584825-05:00","@version":"1","message":"Finished Spring Data repository scanning in 36 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:46.631246615-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:48.126694769-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:49.652566196-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 4.678 seconds (process running for 9.54)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:49.655352836-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:49.68877437-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:49.689296111-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:49.781046167-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:50.163151108-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:50.260630669-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-7","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:50.336833249-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-7","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:50.365460757-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-7","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:50.389661362-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-7","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:50.398435461-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-7","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:50.42618514-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-7","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:11:50.43397145-05:00","@version":"1","message":"Error no esperado al guardar la orden: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-7","level":"ERROR","level_value":40000,"stack_trace":"org.springframework.dao.DataAccessResourceFailureException: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen\n\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxOnErrorResume] :\n\treactor.core.publisher.Flux.onErrorMap\n\torg.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\nError has been observed at the following site(s):\n\t*__Flux.onErrorMap ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\n\t|_                 ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.all(DefaultFetchSpec.java:76)\n\t|_       Flux.last ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_    Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$6(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$7(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:504)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.insert(R2dbcEntityTemplate.java:497)\n\t|_                 ⇢ at org.springframework.data.r2dbc.repository.support.SimpleR2dbcRepository.save(SimpleR2dbcRepository.java:122)\n\t|_                 ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.lambda$decorate$1(RepositoryMethodInvoker.java:222)\n\t*___Mono.usingWhen ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.decorate(RepositoryMethodInvoker.java:219)\nOriginal Stack Trace:\n\t\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\t\tat org.springframework.r2dbc.core.DefaultDatabaseClient.lambda$inConnectionMany$8(DefaultDatabaseClient.java:157)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorMap$29(Flux.java:7353)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorResume$30(Flux.java:7406)\n\t\tat reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.deferredError(FluxUsingWhen.java:403)\n\t\tat reactor.core.publisher.FluxUsingWhen$RollbackInner.onComplete(FluxUsingWhen.java:480)\n\t\tat reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2231)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onComplete(MonoIgnoreElements.java:89)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onComplete(FluxMapFuseable.java:152)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onComplete(FluxFilterFuseable.java:171)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onComplete(FluxFilterFuseable.java:391)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onComplete(FluxMapFuseable.java:350)\n\t\tat reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2573)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.request(FluxMapFuseable.java:360)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.request(FluxFilterFuseable.java:411)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.request(FluxFilterFuseable.java:191)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onSubscribe(MonoIgnoreElements.java:72)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onSubscribe(FluxFilterFuseable.java:87)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onSubscribe(FluxFilterFuseable.java:305)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onSubscribe(FluxMapFuseable.java:265)\n\t\tat reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:53)\n\t\tat reactor.core.publisher.Mono.subscribe(Mono.java:4576)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onError(FluxUsingWhen.java:368)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.checkTerminated(FluxFlatMap.java:846)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:612)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:592)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.innerError(FluxFlatMap.java:867)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapInner.onError(FluxFlatMap.java:994)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onError(FluxHandleFuseable.java:229)\n\t\tat reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onError(MonoFlatMapMany.java:256)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:201)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: io.r2dbc.postgresql.ExceptionFactory$PostgresqlNonTransientResourceException: El motivo no coincide con el almacen\n\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxHandleFuseable] :\n\treactor.core.publisher.Flux.handle\n\tio.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\nError has been observed at the following site(s):\n\t*_______Flux.handle ⇢ at io.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\n\t*__Mono.flatMapMany ⇢ at io.r2dbc.postgresql.PostgresqlStatement.lambda$execute$8(PostgresqlStatement.java:220)\n\t|_      Flux.handle ⇢ at io.r2dbc.postgresql.PostgresqlResult.map(PostgresqlResult.java:113)\n\t*______Flux.flatMap ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.lambda$all$1(DefaultFetchSpec.java:78)\n\t*____Flux.usingWhen ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:144)\nOriginal Stack Trace:\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:65)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.handleErrorResponse(ExceptionFactory.java:132)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:179)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\n","application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:18.665388166-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:18.7514938-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 829357 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:18.752140687-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:18.753034056-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:19.317552671-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:19.360559733-05:00","@version":"1","message":"Finished Spring Data repository scanning in 36 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:20.021827602-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:21.664437074-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.197781515-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 4.922 seconds (process running for 9.607)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.20193665-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.234385974-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.234723439-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.317866077-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.66500854-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.789783647-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.873146388-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.908117485-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.924615907-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.941774739-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.979175949-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:23.997986724-05:00","@version":"1","message":"Error no esperado al guardar la orden: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"ERROR","level_value":40000,"stack_trace":"org.springframework.dao.DataAccessResourceFailureException: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen\n\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxOnErrorResume] :\n\treactor.core.publisher.Flux.onErrorMap\n\torg.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\nError has been observed at the following site(s):\n\t*__Flux.onErrorMap ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\n\t|_                 ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.all(DefaultFetchSpec.java:76)\n\t|_       Flux.last ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_    Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$6(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$7(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:504)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.insert(R2dbcEntityTemplate.java:497)\n\t|_                 ⇢ at org.springframework.data.r2dbc.repository.support.SimpleR2dbcRepository.save(SimpleR2dbcRepository.java:122)\n\t|_                 ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.lambda$decorate$1(RepositoryMethodInvoker.java:222)\n\t*___Mono.usingWhen ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.decorate(RepositoryMethodInvoker.java:219)\nOriginal Stack Trace:\n\t\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\t\tat org.springframework.r2dbc.core.DefaultDatabaseClient.lambda$inConnectionMany$8(DefaultDatabaseClient.java:157)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorMap$29(Flux.java:7353)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorResume$30(Flux.java:7406)\n\t\tat reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.deferredError(FluxUsingWhen.java:403)\n\t\tat reactor.core.publisher.FluxUsingWhen$RollbackInner.onComplete(FluxUsingWhen.java:480)\n\t\tat reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2231)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onComplete(MonoIgnoreElements.java:89)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onComplete(FluxMapFuseable.java:152)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onComplete(FluxFilterFuseable.java:171)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onComplete(FluxFilterFuseable.java:391)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onComplete(FluxMapFuseable.java:350)\n\t\tat reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2573)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.request(FluxMapFuseable.java:360)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.request(FluxFilterFuseable.java:411)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.request(FluxFilterFuseable.java:191)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onSubscribe(MonoIgnoreElements.java:72)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onSubscribe(FluxFilterFuseable.java:87)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onSubscribe(FluxFilterFuseable.java:305)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onSubscribe(FluxMapFuseable.java:265)\n\t\tat reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:53)\n\t\tat reactor.core.publisher.Mono.subscribe(Mono.java:4576)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onError(FluxUsingWhen.java:368)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.checkTerminated(FluxFlatMap.java:846)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:612)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:592)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.innerError(FluxFlatMap.java:867)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapInner.onError(FluxFlatMap.java:994)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onError(FluxHandleFuseable.java:229)\n\t\tat reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onError(MonoFlatMapMany.java:256)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:201)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: io.r2dbc.postgresql.ExceptionFactory$PostgresqlNonTransientResourceException: El motivo no coincide con el almacen\n\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxHandleFuseable] :\n\treactor.core.publisher.Flux.handle\n\tio.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\nError has been observed at the following site(s):\n\t*_______Flux.handle ⇢ at io.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\n\t*__Mono.flatMapMany ⇢ at io.r2dbc.postgresql.PostgresqlStatement.lambda$execute$8(PostgresqlStatement.java:220)\n\t|_      Flux.handle ⇢ at io.r2dbc.postgresql.PostgresqlResult.map(PostgresqlResult.java:113)\n\t*______Flux.flatMap ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.lambda$all$1(DefaultFetchSpec.java:78)\n\t*____Flux.usingWhen ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:144)\nOriginal Stack Trace:\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:65)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.handleErrorResponse(ExceptionFactory.java:132)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:179)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\n","application":"module-almacen"}
{"@timestamp":"2025-05-18T11:12:24.125739426-05:00","@version":"1","message":"Custom destroy method 'dispose' on bean with name 'connectionFactory' propagated an exception: java.lang.IllegalStateException: channel not registered to an event loop","logger_name":"org.springframework.beans.factory.support.DisposableBeanAdapter","thread_name":"SpringApplicationShutdownHook","level":"WARN","level_value":30000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:01.895082787-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:01.994679358-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 831036 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:01.995359026-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:01.996151212-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:02.764171861-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:02.888290779-05:00","@version":"1","message":"Finished Spring Data repository scanning in 113 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:03.538856262-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:05.13127122-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:06.72491384-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 5.492 seconds (process running for 9.82)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:06.729285596-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:06.762636558-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:06.763074396-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:06.852922402-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:07.190061508-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:07.333848559-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:07.402466331-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:07.432749666-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:07.452601337-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:07.467142257-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:07.498892018-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:07.510324743-05:00","@version":"1","message":"Error no esperado al guardar la orden: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"ERROR","level_value":40000,"stack_trace":"org.springframework.dao.DataAccessResourceFailureException: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen\n\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxOnErrorResume] :\n\treactor.core.publisher.Flux.onErrorMap\n\torg.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\nError has been observed at the following site(s):\n\t*__Flux.onErrorMap ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\n\t|_                 ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.all(DefaultFetchSpec.java:76)\n\t|_       Flux.last ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_    Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$6(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$7(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:504)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.insert(R2dbcEntityTemplate.java:497)\n\t|_                 ⇢ at org.springframework.data.r2dbc.repository.support.SimpleR2dbcRepository.save(SimpleR2dbcRepository.java:122)\n\t|_                 ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.lambda$decorate$1(RepositoryMethodInvoker.java:222)\n\t*___Mono.usingWhen ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.decorate(RepositoryMethodInvoker.java:219)\nOriginal Stack Trace:\n\t\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\t\tat org.springframework.r2dbc.core.DefaultDatabaseClient.lambda$inConnectionMany$8(DefaultDatabaseClient.java:157)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorMap$29(Flux.java:7353)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorResume$30(Flux.java:7406)\n\t\tat reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.deferredError(FluxUsingWhen.java:403)\n\t\tat reactor.core.publisher.FluxUsingWhen$RollbackInner.onComplete(FluxUsingWhen.java:480)\n\t\tat reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2231)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onComplete(MonoIgnoreElements.java:89)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onComplete(FluxMapFuseable.java:152)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onComplete(FluxFilterFuseable.java:171)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onComplete(FluxFilterFuseable.java:391)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onComplete(FluxMapFuseable.java:350)\n\t\tat reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2573)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.request(FluxMapFuseable.java:360)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.request(FluxFilterFuseable.java:411)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.request(FluxFilterFuseable.java:191)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onSubscribe(MonoIgnoreElements.java:72)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onSubscribe(FluxFilterFuseable.java:87)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onSubscribe(FluxFilterFuseable.java:305)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onSubscribe(FluxMapFuseable.java:265)\n\t\tat reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:53)\n\t\tat reactor.core.publisher.Mono.subscribe(Mono.java:4576)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onError(FluxUsingWhen.java:368)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.checkTerminated(FluxFlatMap.java:846)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:612)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:592)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.innerError(FluxFlatMap.java:867)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapInner.onError(FluxFlatMap.java:994)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onError(FluxHandleFuseable.java:229)\n\t\tat reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onError(MonoFlatMapMany.java:256)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:201)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: io.r2dbc.postgresql.ExceptionFactory$PostgresqlNonTransientResourceException: El motivo no coincide con el almacen\n\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxHandleFuseable] :\n\treactor.core.publisher.Flux.handle\n\tio.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\nError has been observed at the following site(s):\n\t*_______Flux.handle ⇢ at io.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\n\t*__Mono.flatMapMany ⇢ at io.r2dbc.postgresql.PostgresqlStatement.lambda$execute$8(PostgresqlStatement.java:220)\n\t|_      Flux.handle ⇢ at io.r2dbc.postgresql.PostgresqlResult.map(PostgresqlResult.java:113)\n\t*______Flux.flatMap ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.lambda$all$1(DefaultFetchSpec.java:78)\n\t*____Flux.usingWhen ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:144)\nOriginal Stack Trace:\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:65)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.handleErrorResponse(ExceptionFactory.java:132)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:179)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\n","application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:44.362924199-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:44.472054545-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 831917 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:44.472778795-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:44.473536713-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:45.021197019-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:45.139002818-05:00","@version":"1","message":"Finished Spring Data repository scanning in 109 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:45.983874368-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:47.688500311-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:49.104108935-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 5.614 seconds (process running for 9.221)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:49.107138739-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:49.136293351-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:49.136872193-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:49.204572974-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:49.781210922-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:49.873496625-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:49.965653989-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:50.001783557-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:50.020547268-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:50.036688609-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:50.070080466-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T11:14:50.077925625-05:00","@version":"1","message":"Error no esperado al guardar la orden: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"ERROR","level_value":40000,"stack_trace":"org.springframework.dao.DataAccessResourceFailureException: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen\n\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxOnErrorResume] :\n\treactor.core.publisher.Flux.onErrorMap\n\torg.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\nError has been observed at the following site(s):\n\t*__Flux.onErrorMap ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\n\t|_                 ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.all(DefaultFetchSpec.java:76)\n\t|_       Flux.last ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_    Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$6(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$7(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:504)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.insert(R2dbcEntityTemplate.java:497)\n\t|_                 ⇢ at org.springframework.data.r2dbc.repository.support.SimpleR2dbcRepository.save(SimpleR2dbcRepository.java:122)\n\t|_                 ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.lambda$decorate$1(RepositoryMethodInvoker.java:222)\n\t*___Mono.usingWhen ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.decorate(RepositoryMethodInvoker.java:219)\nOriginal Stack Trace:\n\t\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\t\tat org.springframework.r2dbc.core.DefaultDatabaseClient.lambda$inConnectionMany$8(DefaultDatabaseClient.java:157)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorMap$29(Flux.java:7353)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorResume$30(Flux.java:7406)\n\t\tat reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.deferredError(FluxUsingWhen.java:403)\n\t\tat reactor.core.publisher.FluxUsingWhen$RollbackInner.onComplete(FluxUsingWhen.java:480)\n\t\tat reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2231)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onComplete(MonoIgnoreElements.java:89)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onComplete(FluxMapFuseable.java:152)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onComplete(FluxFilterFuseable.java:171)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onComplete(FluxFilterFuseable.java:391)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onComplete(FluxMapFuseable.java:350)\n\t\tat reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2573)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.request(FluxMapFuseable.java:360)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.request(FluxFilterFuseable.java:411)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.request(FluxFilterFuseable.java:191)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onSubscribe(MonoIgnoreElements.java:72)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onSubscribe(FluxFilterFuseable.java:87)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onSubscribe(FluxFilterFuseable.java:305)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onSubscribe(FluxMapFuseable.java:265)\n\t\tat reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:53)\n\t\tat reactor.core.publisher.Mono.subscribe(Mono.java:4576)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onError(FluxUsingWhen.java:368)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.checkTerminated(FluxFlatMap.java:846)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:612)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:592)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.innerError(FluxFlatMap.java:867)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapInner.onError(FluxFlatMap.java:994)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onError(FluxHandleFuseable.java:229)\n\t\tat reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onError(MonoFlatMapMany.java:256)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:201)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: io.r2dbc.postgresql.ExceptionFactory$PostgresqlNonTransientResourceException: El motivo no coincide con el almacen\n\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxHandleFuseable] :\n\treactor.core.publisher.Flux.handle\n\tio.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\nError has been observed at the following site(s):\n\t*_______Flux.handle ⇢ at io.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\n\t*__Mono.flatMapMany ⇢ at io.r2dbc.postgresql.PostgresqlStatement.lambda$execute$8(PostgresqlStatement.java:220)\n\t|_      Flux.handle ⇢ at io.r2dbc.postgresql.PostgresqlResult.map(PostgresqlResult.java:113)\n\t*______Flux.flatMap ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.lambda$all$1(DefaultFetchSpec.java:78)\n\t*____Flux.usingWhen ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:144)\nOriginal Stack Trace:\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:65)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.handleErrorResponse(ExceptionFactory.java:132)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:179)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\n","application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:48.912293726-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:49.070878846-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 51309 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:49.073264588-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:49.074321842-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:49.772263041-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:49.897422254-05:00","@version":"1","message":"Finished Spring Data repository scanning in 119 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:50.557222523-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:52.279266-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:53.724511844-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 5.722 seconds (process running for 9.626)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:53.728124318-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:53.766309993-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:53.766891981-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:53.875828384-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:54.539391755-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:54.690343972-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:54.792955023-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:54.826362806-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:54.841654519-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:54.85405866-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:54.883202612-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:26:54.890673787-05:00","@version":"1","message":"Error no esperado al guardar la orden: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"ERROR","level_value":40000,"stack_trace":"org.springframework.dao.DataAccessResourceFailureException: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen\n\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxOnErrorResume] :\n\treactor.core.publisher.Flux.onErrorMap\n\torg.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\nError has been observed at the following site(s):\n\t*__Flux.onErrorMap ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\n\t|_                 ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.all(DefaultFetchSpec.java:76)\n\t|_       Flux.last ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_    Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$6(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$7(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:504)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.insert(R2dbcEntityTemplate.java:497)\n\t|_                 ⇢ at org.springframework.data.r2dbc.repository.support.SimpleR2dbcRepository.save(SimpleR2dbcRepository.java:122)\n\t|_                 ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.lambda$decorate$1(RepositoryMethodInvoker.java:222)\n\t*___Mono.usingWhen ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.decorate(RepositoryMethodInvoker.java:219)\nOriginal Stack Trace:\n\t\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\t\tat org.springframework.r2dbc.core.DefaultDatabaseClient.lambda$inConnectionMany$8(DefaultDatabaseClient.java:157)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorMap$29(Flux.java:7353)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorResume$30(Flux.java:7406)\n\t\tat reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.deferredError(FluxUsingWhen.java:403)\n\t\tat reactor.core.publisher.FluxUsingWhen$RollbackInner.onComplete(FluxUsingWhen.java:480)\n\t\tat reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2231)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onComplete(MonoIgnoreElements.java:89)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onComplete(FluxMapFuseable.java:152)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onComplete(FluxFilterFuseable.java:171)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onComplete(FluxFilterFuseable.java:391)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onComplete(FluxMapFuseable.java:350)\n\t\tat reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2573)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.request(FluxMapFuseable.java:360)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.request(FluxFilterFuseable.java:411)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.request(FluxFilterFuseable.java:191)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onSubscribe(MonoIgnoreElements.java:72)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onSubscribe(FluxFilterFuseable.java:87)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onSubscribe(FluxFilterFuseable.java:305)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onSubscribe(FluxMapFuseable.java:265)\n\t\tat reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:53)\n\t\tat reactor.core.publisher.Mono.subscribe(Mono.java:4576)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onError(FluxUsingWhen.java:368)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.checkTerminated(FluxFlatMap.java:846)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:612)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:592)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.innerError(FluxFlatMap.java:867)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapInner.onError(FluxFlatMap.java:994)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onError(FluxHandleFuseable.java:229)\n\t\tat reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onError(MonoFlatMapMany.java:256)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:201)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: io.r2dbc.postgresql.ExceptionFactory$PostgresqlNonTransientResourceException: El motivo no coincide con el almacen\n\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxHandleFuseable] :\n\treactor.core.publisher.Flux.handle\n\tio.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\nError has been observed at the following site(s):\n\t*_______Flux.handle ⇢ at io.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\n\t*__Mono.flatMapMany ⇢ at io.r2dbc.postgresql.PostgresqlStatement.lambda$execute$8(PostgresqlStatement.java:220)\n\t|_      Flux.handle ⇢ at io.r2dbc.postgresql.PostgresqlResult.map(PostgresqlResult.java:113)\n\t*______Flux.flatMap ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.lambda$all$1(DefaultFetchSpec.java:78)\n\t*____Flux.usingWhen ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:144)\nOriginal Stack Trace:\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:65)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.handleErrorResponse(ExceptionFactory.java:132)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:179)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\n","application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:28.549796775-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:28.63146671-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 63071 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:28.632223919-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:28.632995026-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:29.2168086-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:29.327357914-05:00","@version":"1","message":"Finished Spring Data repository scanning in 102 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:29.973154965-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:31.586333112-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:33.17083883-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 5.454 seconds (process running for 8.759)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:33.175372604-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:33.218343509-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:33.218987004-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:33.301790424-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:33.901072826-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:34.016111902-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:34.101808241-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:34.159515416-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:34.181933011-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:34.197747709-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:34.23440359-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:34.242322627-05:00","@version":"1","message":"Error no esperado al guardar la orden: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"ERROR","level_value":40000,"stack_trace":"org.springframework.dao.DataAccessResourceFailureException: executeMany; SQL [INSERT INTO almacenes.ordeningreso (id_cliente, id_motivo, id_comprobante, nu_comprobante, observacion, fec_ingreso, fec_ref, nu_serie) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)]; El motivo no coincide con el almacen\n\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxOnErrorResume] :\n\treactor.core.publisher.Flux.onErrorMap\n\torg.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\nError has been observed at the following site(s):\n\t*__Flux.onErrorMap ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:156)\n\t|_                 ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.all(DefaultFetchSpec.java:76)\n\t|_       Flux.last ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_    Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:573)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$6(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.lambda$doInsert$7(R2dbcEntityTemplate.java:513)\n\t*_____Mono.flatMap ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.doInsert(R2dbcEntityTemplate.java:504)\n\t|_                 ⇢ at org.springframework.data.r2dbc.core.R2dbcEntityTemplate.insert(R2dbcEntityTemplate.java:497)\n\t|_                 ⇢ at org.springframework.data.r2dbc.repository.support.SimpleR2dbcRepository.save(SimpleR2dbcRepository.java:122)\n\t|_                 ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.lambda$decorate$1(RepositoryMethodInvoker.java:222)\n\t*___Mono.usingWhen ⇢ at org.springframework.data.repository.core.support.RepositoryMethodInvoker$ReactiveInvocationListenerDecorator.decorate(RepositoryMethodInvoker.java:219)\nOriginal Stack Trace:\n\t\tat org.springframework.r2dbc.connection.ConnectionFactoryUtils.convertR2dbcException(ConnectionFactoryUtils.java:241)\n\t\tat org.springframework.r2dbc.core.DefaultDatabaseClient.lambda$inConnectionMany$8(DefaultDatabaseClient.java:157)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorMap$29(Flux.java:7353)\n\t\tat reactor.core.publisher.Flux.lambda$onErrorResume$30(Flux.java:7406)\n\t\tat reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:94)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.deferredError(FluxUsingWhen.java:403)\n\t\tat reactor.core.publisher.FluxUsingWhen$RollbackInner.onComplete(FluxUsingWhen.java:480)\n\t\tat reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2231)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onComplete(MonoIgnoreElements.java:89)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onComplete(FluxMapFuseable.java:152)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onComplete(FluxFilterFuseable.java:171)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onComplete(FluxFilterFuseable.java:391)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onComplete(FluxMapFuseable.java:350)\n\t\tat reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2573)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.request(FluxMapFuseable.java:360)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.request(FluxFilterFuseable.java:411)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.request(FluxFilterFuseable.java:191)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)\n\t\tat reactor.core.publisher.MonoIgnoreElements$IgnoreElementsSubscriber.onSubscribe(MonoIgnoreElements.java:72)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableSubscriber.onSubscribe(FluxFilterFuseable.java:87)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onSubscribe(FluxFilterFuseable.java:305)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onSubscribe(FluxMapFuseable.java:265)\n\t\tat reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDeferContextual.subscribe(MonoDeferContextual.java:55)\n\t\tat reactor.core.publisher.InternalMonoOperator.subscribe(InternalMonoOperator.java:76)\n\t\tat reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:53)\n\t\tat reactor.core.publisher.Mono.subscribe(Mono.java:4576)\n\t\tat reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onError(FluxUsingWhen.java:368)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.checkTerminated(FluxFlatMap.java:846)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:612)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:592)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapMain.innerError(FluxFlatMap.java:867)\n\t\tat reactor.core.publisher.FluxFlatMap$FlatMapInner.onError(FluxFlatMap.java:994)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onError(FluxHandleFuseable.java:229)\n\t\tat reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onError(MonoFlatMapMany.java:256)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:201)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\nCaused by: io.r2dbc.postgresql.ExceptionFactory$PostgresqlNonTransientResourceException: El motivo no coincide con el almacen\n\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\tSuppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException: \nAssembly trace from producer [reactor.core.publisher.FluxHandleFuseable] :\n\treactor.core.publisher.Flux.handle\n\tio.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\nError has been observed at the following site(s):\n\t*_______Flux.handle ⇢ at io.r2dbc.postgresql.ExtendedFlowDelegate.runQuery(ExtendedFlowDelegate.java:125)\n\t*__Mono.flatMapMany ⇢ at io.r2dbc.postgresql.PostgresqlStatement.lambda$execute$8(PostgresqlStatement.java:220)\n\t|_      Flux.handle ⇢ at io.r2dbc.postgresql.PostgresqlResult.map(PostgresqlResult.java:113)\n\t*______Flux.flatMap ⇢ at org.springframework.r2dbc.core.DefaultFetchSpec.lambda$all$1(DefaultFetchSpec.java:78)\n\t*____Flux.usingWhen ⇢ at org.springframework.r2dbc.core.DefaultDatabaseClient.inConnectionMany(DefaultDatabaseClient.java:144)\nOriginal Stack Trace:\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:109)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.createException(ExceptionFactory.java:65)\n\t\tat io.r2dbc.postgresql.ExceptionFactory.handleErrorResponse(ExceptionFactory.java:132)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:179)\n\t\tat reactor.core.publisher.FluxFilterFuseable$FilterFuseableConditionalSubscriber.onNext(FluxFilterFuseable.java:337)\n\t\tat reactor.core.publisher.FluxContextWrite$ContextWriteSubscriber.onNext(FluxContextWrite.java:107)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat io.r2dbc.postgresql.util.FluxDiscardOnCancel$FluxDiscardOnCancelSubscriber.onNext(FluxDiscardOnCancel.java:91)\n\t\tat reactor.core.publisher.FluxDoFinally$DoFinallySubscriber.onNext(FluxDoFinally.java:113)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:880)\n\t\tat reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:805)\n\t\tat reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:163)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$Conversation.emit(ReactorNettyClient.java:696)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.emit(ReactorNettyClient.java:948)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:822)\n\t\tat io.r2dbc.postgresql.client.ReactorNettyClient$BackendMessageSubscriber.onNext(ReactorNettyClient.java:728)\n\t\tat reactor.core.publisher.FluxHandleFuseable$HandleFuseableSubscriber.onNext(FluxHandleFuseable.java:194)\n\t\tat reactor.core.publisher.FluxPeekFuseable$PeekFuseableConditionalSubscriber.onNext(FluxPeekFuseable.java:503)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.core.publisher.FluxMapFuseable$MapFuseableConditionalSubscriber.onNext(FluxMapFuseable.java:299)\n\t\tat reactor.netty.channel.FluxReceive.drainReceiver(FluxReceive.java:292)\n\t\tat reactor.netty.channel.FluxReceive.onInboundNext(FluxReceive.java:401)\n\t\tat reactor.netty.channel.ChannelOperations.onInboundNext(ChannelOperations.java:435)\n\t\tat reactor.netty.channel.ChannelOperationsHandler.channelRead(ChannelOperationsHandler.java:115)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:346)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:333)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:455)\n\t\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\n\t\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1357)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\n\t\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\n\t\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:868)\n\t\tat io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:799)\n\t\tat io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:501)\n\t\tat io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:399)\n\t\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:998)\n\t\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n\t\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\t\tat java.base/java.lang.Thread.run(Thread.java:1583)\n","application":"module-almacen"}
{"@timestamp":"2025-05-18T21:44:34.372104942-05:00","@version":"1","message":"Custom destroy method 'dispose' on bean with name 'connectionFactory' propagated an exception: reactor.netty.channel.AbortedException: Connection has been closed BEFORE send operation","logger_name":"org.springframework.beans.factory.support.DisposableBeanAdapter","thread_name":"SpringApplicationShutdownHook","level":"WARN","level_value":30000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:33.038135589-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:33.137766935-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 65002 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:33.13822574-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:33.13882687-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:33.706251111-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:33.79877118-05:00","@version":"1","message":"Finished Spring Data repository scanning in 84 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:34.389525247-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:35.885817893-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:37.327160753-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 5.089 seconds (process running for 8.414)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:37.330194291-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:37.359695753-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:37.360240544-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:37.455562694-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:38.119659741-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:38.23468038-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:38.350408726-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:38.386655464-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:38.405163771-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:38.421532011-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:46:38.525342485-05:00","@version":"1","message":"Custom destroy method 'dispose' on bean with name 'connectionFactory' propagated an exception: reactor.netty.channel.AbortedException: Connection has been closed BEFORE send operation","logger_name":"org.springframework.beans.factory.support.DisposableBeanAdapter","thread_name":"SpringApplicationShutdownHook","level":"WARN","level_value":30000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:41.341479607-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:41.418236221-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 66483 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:41.418961609-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:41.419759024-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:41.951203431-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:42.050930081-05:00","@version":"1","message":"Finished Spring Data repository scanning in 92 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:42.686890338-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:44.295695168-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:45.756159646-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 5.314 seconds (process running for 8.676)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:45.759586848-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:45.791309671-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:45.791967162-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:45.886830225-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:46.660113763-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:46.800237382-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-2","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:46.868114468-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-2","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:46.902726701-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-2","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:46.920569779-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-2","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:47:46.932484715-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-2","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:28.598342884-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:28.676092318-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 67552 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:28.676722122-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:28.678093689-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:29.196582014-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:29.274036003-05:00","@version":"1","message":"Finished Spring Data repository scanning in 70 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:29.89533239-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:31.754189147-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:33.29903516-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 5.383 seconds (process running for 9.566)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:33.302196464-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:33.344924335-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:33.345463587-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:33.446548973-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:33.752590877-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:33.857352244-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:33.934505855-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:33.968352677-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:33.981723065-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:48:33.994500373-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:05.788813545-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:05.899863284-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 68432 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:05.901517262-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:05.903133898-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:06.770863299-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:06.886313988-05:00","@version":"1","message":"Finished Spring Data repository scanning in 109 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:07.760805927-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:09.553168586-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:11.598603548-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 6.499 seconds (process running for 10.938)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:11.601462725-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:11.631664525-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:11.632025282-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:11.717350686-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:12.12385398-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:12.225871932-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:12.308243476-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:12.342283138-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:12.354022844-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:12.363729608-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:12.448234506-05:00","@version":"1","message":"Custom destroy method 'dispose' on bean with name 'connectionFactory' propagated an exception: reactor.netty.channel.AbortedException: io.netty.channel.StacklessClosedChannelException","logger_name":"org.springframework.beans.factory.support.DisposableBeanAdapter","thread_name":"SpringApplicationShutdownHook","level":"WARN","level_value":30000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:37.523071937-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:37.591432465-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 69425 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:37.591943675-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:37.592391896-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:38.200536463-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:38.252348332-05:00","@version":"1","message":"Finished Spring Data repository scanning in 45 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:38.866970248-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:40.319032282-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:41.735862662-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 4.646 seconds (process running for 9.166)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:41.738879723-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:41.771261845-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:41.771668628-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:41.852968214-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:42.165972156-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:42.277915776-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:42.376293517-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:42.413373732-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:42.431639082-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:42.443885986-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:49:42.5271829-05:00","@version":"1","message":"Custom destroy method 'dispose' on bean with name 'connectionFactory' propagated an exception: reactor.netty.channel.AbortedException: Connection has been closed BEFORE send operation","logger_name":"org.springframework.beans.factory.support.DisposableBeanAdapter","thread_name":"SpringApplicationShutdownHook","level":"WARN","level_value":30000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:51.546169523-05:00","@version":"1","message":"HV000001: Hibernate Validator 8.0.2.Final","logger_name":"org.hibernate.validator.internal.util.Version","thread_name":"background-preinit","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:51.642296302-05:00","@version":"1","message":"Starting OrdenIngresoLogisticaPersistenceAdapterTest using Java 21.0.6 with PID 71270 (started by developer01 in /home/developer01/monolith-module-v1/module-almacen)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:51.642930704-05:00","@version":"1","message":"Running with Spring Boot v3.4.5, Spring v6.2.3","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:51.643608317-05:00","@version":"1","message":"The following 1 profile is active: \"test-almacenes\"","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:52.200920167-05:00","@version":"1","message":"Bootstrapping Spring Data R2DBC repositories in DEFAULT mode.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:52.238869249-05:00","@version":"1","message":"Finished Spring Data repository scanning in 33 ms. Found 8 R2DBC repository interfaces.","logger_name":"org.springframework.data.repository.config.RepositoryConfigurationDelegate","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:52.861079449-05:00","@version":"1","message":"BeanFactory id=2be7b9c0-af52-37a4-82ae-b94fc5b71109","logger_name":"org.springframework.cloud.context.scope.GenericScope","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:54.595467192-05:00","@version":"1","message":"✅ Conexión con Kafka establecida correctamente","logger_name":"com.walrex.module_almacen.common.kafka.producer.factory.AlmacenKafkaProducerFactory","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:56.189156513-05:00","@version":"1","message":"Started OrdenIngresoLogisticaPersistenceAdapterTest in 5.032 seconds (process running for 9.477)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapterTest","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:56.192397583-05:00","@version":"1","message":"Iniciando consumidor Kafka para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:56.23100105-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:56.231589099-05:00","@version":"1","message":"KafkaAvroDeserializerConfig values: \n\tauto.register.schemas = true\n\tavro.reflection.allow.null = false\n\tavro.use.logical.type.converters = false\n\tbasic.auth.credentials.source = URL\n\tbasic.auth.user.info = [hidden]\n\tbearer.auth.cache.expiry.buffer.seconds = 300\n\tbearer.auth.client.id = null\n\tbearer.auth.client.secret = null\n\tbearer.auth.credentials.source = STATIC_TOKEN\n\tbearer.auth.custom.provider.class = null\n\tbearer.auth.identity.pool.id = null\n\tbearer.auth.issuer.endpoint.url = null\n\tbearer.auth.logical.cluster = null\n\tbearer.auth.scope = null\n\tbearer.auth.scope.claim.name = scope\n\tbearer.auth.sub.claim.name = sub\n\tbearer.auth.token = [hidden]\n\tcontext.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy\n\thttp.connect.timeout.ms = 60000\n\thttp.read.timeout.ms = 60000\n\tid.compatibility.strict = true\n\tkey.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n\tlatest.cache.size = 1000\n\tlatest.cache.ttl.sec = -1\n\tlatest.compatibility.strict = true\n\tmax.retries = 3\n\tmax.schemas.per.subject = 1000\n\tnormalize.schemas = false\n\tpropagate.schema.tags = false\n\tproxy.host = \n\tproxy.port = -1\n\tretries.max.wait.ms = 20000\n\tretries.wait.ms = 1000\n\trule.actions = []\n\trule.executors = []\n\trule.service.loader.enable = true\n\tschema.format = null\n\tschema.reflection = false\n\tschema.registry.basic.auth.user.info = [hidden]\n\tschema.registry.ssl.cipher.suites = null\n\tschema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tschema.registry.ssl.endpoint.identification.algorithm = https\n\tschema.registry.ssl.engine.factory.class = null\n\tschema.registry.ssl.key.password = null\n\tschema.registry.ssl.keymanager.algorithm = SunX509\n\tschema.registry.ssl.keystore.certificate.chain = null\n\tschema.registry.ssl.keystore.key = null\n\tschema.registry.ssl.keystore.location = null\n\tschema.registry.ssl.keystore.password = null\n\tschema.registry.ssl.keystore.type = JKS\n\tschema.registry.ssl.protocol = TLSv1.3\n\tschema.registry.ssl.provider = null\n\tschema.registry.ssl.secure.random.implementation = null\n\tschema.registry.ssl.trustmanager.algorithm = PKIX\n\tschema.registry.ssl.truststore.certificates = null\n\tschema.registry.ssl.truststore.location = null\n\tschema.registry.ssl.truststore.password = null\n\tschema.registry.ssl.truststore.type = JKS\n\tschema.registry.url = [http://localhost:8081]\n\tspecific.avro.key.type = null\n\tspecific.avro.reader = true\n\tspecific.avro.value.type = null\n\tuse.latest.version = true\n\tuse.latest.with.metadata = null\n\tuse.schema.id = -1\n\tvalue.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy\n","logger_name":"io.confluent.kafka.serializers.KafkaAvroDeserializerConfig","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:56.352885383-05:00","@version":"1","message":"Consumidor Kafka iniciado correctamente para el topic: create-ingreso-ajuste","logger_name":"com.walrex.module_almacen.infrastructure.adapters.inbound.consumer.OrdenAjusteInventarioKafkaConsumer","thread_name":"main","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:56.755527777-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-1","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:56.902396589-05:00","@version":"1","message":"Guardando orden de ingreso en la base de datos","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:56.996611036-05:00","@version":"1","message":"Orden de ingreso guardada con ID: 1","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:57.049467337-05:00","@version":"1","message":"✅ Información de conversión encontrada: ArticuloEntity(idArticulo=null, valorConv=3, isMultiplo=1, idTipoProducto=1, idUnidad=1, idUnidadConsumo=6, stock=544982.9000)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:57.069224476-05:00","@version":"1","message":"✅ Información de detalle articulo guarado: DetailsIngresoEntity(id=1, id_ordeningreso=1, id_articulo=289, id_unidad=1, lote=001120-1, peso_ref=null, peso_ingreso=null, peso_dif=null, cantidad=240.0, observacion=null, costo_compra=2.15, status=null, id_kardex=null, id_moneda=2, excento_imp=0)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"DEBUG","level_value":10000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:57.085467772-05:00","@version":"1","message":"✅ Información de kardex guardado: KardexEntity(id_kardex=1, tipo_movimiento=1, detalle=(null) - COMPRAS, cantidad=240.0, costo=2.15, valorTotal=516.0, fecha_movimiento=2025-03-31, id_articulo=289, status=null, id_unidad=1, id_unidad_salida=6, id_almacen=1, saldo_actual=784982.900000, id_documento=1, id_lote=null, id_detalle_documento=1, saldoLote=240000.000000, created_at=null, updated_at=null)","logger_name":"com.walrex.module_almacen.infrastructure.adapters.outbound.persistence.OrdenIngresoLogisticaPersistenceAdapter","thread_name":"reactor-tcp-epoll-8","level":"INFO","level_value":20000,"application":"module-almacen"}
{"@timestamp":"2025-05-18T21:51:57.184361491-05:00","@version":"1","message":"Custom destroy method 'dispose' on bean with name 'connectionFactory' propagated an exception: reactor.netty.channel.AbortedException: Connection has been closed BEFORE send operation","logger_name":"org.springframework.beans.factory.support.DisposableBeanAdapter","thread_name":"SpringApplicationShutdownHook","level":"WARN","level_value":30000,"application":"module-almacen"}
